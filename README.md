## üìö Tabla de Contenido

- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos Previos](#requisitos-previos)
- [Dise√±o del Docker Compose](#dise√±o-del-docker-compose)
  - [Contexto de build](#contexto-de-build)
  - [Servicio Jupyter](#servicio-jupyter)
  - [Servicio API](#servicio-api)
  - [Vol√∫menes nombrados](#vol√∫menes-nombrados)
  - [Dockerfile.jupyter](#dockerfilejupyter)
  - [Dockerfile.api](#dockerfileapi)
  - [Flujo de comunicaci√≥n entre servicios](#flujo-de-comunicaci√≥n-entre-servicios)
- [Construcci√≥n y Despliegue](#construcci√≥n-y-despliegue)
  - [1. Construir y levantar los servicios](#1-construir-y-levantar-los-servicios)
  - [2. Reconstruir solo un servicio](#2-reconstruir-solo-un-servicio)
  - [3. Detener los servicios](#3-detener-los-servicios)
  - [4. Entrenar los modelos](#4-entrenar-los-modelos)
- [Entrenamiento de Modelos ‚Äî Clase `ModelTrainer`](#entrenamiento-de-modelos--clase-modeltrainer)
  - [Inicializaci√≥n](#inicializaci√≥n)
  - [M√©todo principal: `train_and_save()`](#m√©todo-principal-train_and_save)
  - [Agregar un nuevo modelo](#agregar-un-nuevo-modelo)
- [Descubrimiento de Modelos y M√©tricas en la API](#descubrimiento-de-modelos-y-m√©tricas-en-la-api)
  - [Descubrimiento de modelos (`discover_models`)](#descubrimiento-de-modelos-discover_models)
  - [Carga de m√©tricas (`load_metrics`)](#carga-de-m√©tricas-load_metrics)
  - [Flujo completo](#flujo-completo)
- [Pruebas de la API](#pruebas-de-la-api)
  - [Listar modelos disponibles](#listar-modelos-disponibles)
  - [Clasificar un ping√ºino](#clasificar-un-ping√ºino)
  - [Documentaci√≥n interactiva](#documentaci√≥n-interactiva)
- [Registro de Resultados (Logging de Predicciones)](#registro-de-resultados-logging-de-predicciones)
  - [C√≥mo funciona](#c√≥mo-funciona)
  - [Ejemplo de una l√≠nea en predictionslog](#ejemplo-de-una-l√≠nea-en-predictionslog)
  - [Persistencia del log](#persistencia-del-log)
- [Mapeo de Variables](#mapeo-de-variables)
- [Vol√∫menes Compartidos](#vol√∫menes-compartidos)
- [Notas](#notas)



# Penguin Classifier ‚Äî MLOps Taller 2

Proyecto de clasificaci√≥n de especies de ping√ºinos usando modelos de Machine Learning, desplegado con Docker Compose. Incluye un entorno Jupyter para entrenamiento y una API FastAPI para inferencia en tiempo real.

## Arquitectura


![Arquitectura del Proyecto](Imagenes/Arquitectura.png)


Ambos servicios comparten vol√∫menes Docker para modelos, reportes, datos y resultados.

## Estructura del Proyecto

```
MLOps_Taller2/
‚îú‚îÄ‚îÄ API/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                          # Endpoints FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ model_utils.py              # Carga de modelos, m√©tricas, scaler
‚îÇ       ‚îî‚îÄ‚îÄ logger.py                   # Clase PredictionLogger
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ penguins_v1.csv                 # Dataset de ping√ºinos
‚îú‚îÄ‚îÄ Docker/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml              # Orquestaci√≥n de servicios
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.api                  # Imagen de la API (python:3.13-slim)
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.jupyter              # Imagen de Jupyter (python:3.13-slim)
‚îú‚îÄ‚îÄ jupyter/
‚îÇ   ‚îî‚îÄ‚îÄ notebooks/
‚îÇ       ‚îú‚îÄ‚îÄ train.ipynb                 # Notebook de entrenamiento
‚îÇ       ‚îî‚îÄ‚îÄ utils/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îî‚îÄ‚îÄ model_trainer.py        # Clase ModelTrainer
‚îî‚îÄ‚îÄ README.md
```

## Requisitos Previos

- [Docker](https://docs.docker.com/get-docker/) y [Docker Compose](https://docs.docker.com/compose/install/)

## Dise√±o del Docker Compose

El archivo `Docker/docker-compose.yml` contiene dos servicios que se comunican a trav√©s de vol√∫menes compartidos.

### Contexto de build

Ambos servicios usan `context: ..` (la ra√≠z del proyecto) como contexto de build, porque los Dockerfiles necesitan acceder a carpetas hermanas (`API/`, `data/`, `jupyter/`):

```yaml
services:
  jupyter:
    build:
      context: ..                        # ra√≠z del proyecto
      dockerfile: Docker/Dockerfile.jupyter
  api:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.api
```

Esto permite que cada Dockerfile copie archivos desde cualquier carpeta del proyecto sin necesidad de mover archivos.

### Servicio Jupyter

```yaml
jupyter:
  ports:
    - "8888:8888"
  volumes:
    - shared_models:/app/models
    - shared_report:/app/report
    - shared_data:/app/data
    - shared_results:/app/results
  environment:
    - JUPYTER_TOKEN=mlops12345
```

- Expone el puerto `8888` para acceder a Jupyter Lab desde el navegador.
- Monta 4 vol√∫menes para que los artefactos generados (modelos `.pkl`, m√©tricas, logs) persistan y sean accesibles por la API.
- El token de acceso se configura v√≠a variable de entorno.

### Servicio API

```yaml
api:
  ports:
    - "8000:8000"
  volumes:
    - shared_models:/app/models
    - shared_report:/app/report
    - shared_results:/app/results
  depends_on:
    - jupyter
```

- Expone el puerto `8000` para recibir peticiones HTTP.
- Monta los mismos vol√∫menes de modelos y reportes.
- `depends_on: jupyter` asegura que el contenedor de Jupyter se inicie primero, aunque no garantiza que los modelos est√©n entrenados ‚Äî eso requiere ejecuci√≥n manual del notebook.

### Vol√∫menes nombrados

```yaml
volumes:
  shared_models:    # Pipelines .pkl entrenados
  shared_report:    # model_metrics.pkl con m√©tricas
  shared_data:      # Dataset penguins_v1.csv
  shared_results:   # predictions.log
```

Se usan vol√∫menes nombrados para:
- Persistir datos entre reinicios de contenedores (`docker-compose down` conserva los vol√∫menes).
- Compartir artefactos entre servicios sin exponer rutas del host.
- Limpiar todo con `docker-compose down -v` cuando se quiera empezar desde cero.

### Dockerfile.jupyter

```dockerfile
FROM python:3.13-slim
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /usr/local/bin/
WORKDIR /app
RUN uv init --no-readme && \
    uv add jupyterlab pandas numpy scikit-learn matplotlib seaborn joblib
COPY data/penguins_v1.csv /app/data/penguins_v1.csv
COPY jupyter/notebooks/ /app/notebooks/
RUN mkdir -p /app/models
EXPOSE 8888
CMD ["uv", "run", "jupyter", "lab", "--ip=0.0.0.0", "--port=8888", \
     "--no-browser", "--allow-root", "--NotebookApp.token=mlops12345"]
```

- Usa `uv` como gestor de paquetes.
- Copia el dataset y los notebooks dentro de la imagen para que est√©n disponibles sin vol√∫menes adicionales.
- El dataset tambi√©n se monta como volumen, pero la copia en la imagen sirve como fallback.

### Dockerfile.api

```dockerfile
FROM python:3.13-slim
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /usr/local/bin/
WORKDIR /app
RUN uv init --no-readme && \
    uv add fastapi uvicorn scikit-learn joblib numpy pydantic pandas
COPY API/app.py /app/app.py
COPY API/utils/ /app/utils/
RUN mkdir -p /app/models /app/report /app/results
EXPOSE 8000
CMD ["uv", "run", "uvicorn", "app:app", "--host", "0.0.0.0", \
     "--port", "8000", "--reload"]
```

- Instala solo las dependencias necesarias para servir predicciones (sin matplotlib, seaborn ni jupyterlab).
- Crea los directorios que se montar√°n como vol√∫menes para evitar errores si los vol√∫menes est√°n vac√≠os.
- `--reload` permite que uvicorn detecte cambios en `app.py` durante desarrollo.

### Flujo de comunicaci√≥n entre servicios

```
1. docker-compose up --build
   ‚îú‚îÄ‚îÄ Construye imagen jupyter (python + jupyterlab + sklearn)
   ‚îî‚îÄ‚îÄ Construye imagen api (python + fastapi + sklearn)

2. Jupyter arranca primero (api depends_on jupyter)

3. Usuario abre http://localhost:8888 y ejecuta train.ipynb
   ‚îî‚îÄ‚îÄ ModelTrainer guarda pipelines en /app/models/ (volumen shared_models)
   ‚îî‚îÄ‚îÄ ModelTrainer guarda m√©tricas en /app/report/ (volumen shared_report)

4. API en http://localhost:8000 lee los mismos vol√∫menes
   ‚îî‚îÄ‚îÄ GET /models ‚Üí descubre *_model.pkl en /app/models/
   ‚îî‚îÄ‚îÄ POST /classify/{model} ‚Üí carga pipeline, predice, loguea en /app/results/
```

## Construcci√≥n y Despliegue

### 1. Construir y levantar los servicios

```bash
cd MLOps_Taller2/Docker
docker-compose up --build
```

Esto construye ambas im√°genes (basadas en `python:3.13-slim` con `uv` como gestor de paquetes) y levanta:
- Jupyter Lab en `http://localhost:8888` (token: `mlops12345`)

<p align="center">
  <img src="Imagenes/JupyterLab.png" alt="JupyterLab" width="800">
</p>

- API en `http://localhost:8000`

<p align="center">
  <img src="Imagenes/API_penguin_classifier.png" alt="API" width="800">
</p>


### 2. Reconstruir solo un servicio

```bash
docker-compose up --build api       # solo reconstruye la API
docker-compose up --build jupyter   # solo reconstruye Jupyter
```

### 3. Detener los servicios

```bash
docker-compose down
```

Para eliminar tambi√©n los vol√∫menes (modelos, reportes, etc.) y empezar desde cero:

```bash
docker-compose down -v
```

### 4. Entrenar los modelos

Una vez levantados los servicios:

1. Abrir Jupyter Lab en `http://localhost:8888` con el token `mlops12345`.
2. Abrir `notebooks/train.ipynb` y ejecutar todas las celdas.
3. `ModelTrainer` guarda los pipelines en `/app/models/` y las m√©tricas en `/app/report/model_metrics.pkl` (vol√∫menes compartidos).
4. La API detecta los modelos autom√°ticamente sin necesidad de reiniciar.

## Entrenamiento de Modelos ‚Äî Clase `ModelTrainer`

El entrenamiento se centraliza en la clase `ModelTrainer` (`jupyter/notebooks/utils/model_trainer.py`), que encapsula todo el ciclo de vida de un modelo: construcci√≥n del pipeline, entrenamiento, evaluaci√≥n, visualizaci√≥n, persistencia y actualizaci√≥n del reporte de m√©tricas.

### Inicializaci√≥n

```python
from utils.model_trainer import ModelTrainer

trainer = ModelTrainer(
    models_dir="/app/models",              # directorio donde se guardan los .pkl
    report_path="/app/report/model_metrics.pkl"  # archivo de m√©tricas acumuladas
)
```

Al instanciarse, crea autom√°ticamente los directorios si no existen (`os.makedirs`).

### M√©todo principal: `train_and_save()`

```python
rf_metrics = trainer.train_and_save(
    name='randomforest',
    estimator=RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
    X_train=X_train, X_test=X_test,
    y_train=y_train, y_test=y_test,
    scaler=StandardScaler(),
)
```

Este m√©todo ejecuta internamente los siguientes pasos:

1. `_build_pipeline(estimator, scaler)` ‚Äî Construye un `sklearn.pipeline.Pipeline`. Si se pasa un `scaler`, lo agrega como primer paso del pipeline; luego agrega el estimador. Esto garantiza que el escalado quede integrado en el modelo serializado.

2. `pipeline.fit(X_train, y_train)` ‚Äî Entrena el pipeline completo.

3. `_evaluate(pipeline, name, X_train, X_test, y_train, y_test)` ‚Äî Calcula m√©tricas sobre train y test:
   - `train_accuracy`
   - `test_accuracy`, `test_precision`, `test_recall`, `test_f1` (todas con `average="weighted"`)

4. `_show_report(pipeline, name, X_test, y_test)` ‚Äî Imprime el `classification_report` de sklearn y muestra la matriz de confusi√≥n como heatmap con seaborn.

5. `joblib.dump(pipeline, "{name}_model.pkl")` ‚Äî Serializa el pipeline completo (scaler + modelo) en el volumen compartido `/app/models/`.

6. `_update_report(metrics)` ‚Äî Actualiza el archivo `model_metrics.pkl`:
   - Si ya existe un registro para ese modelo, lo reemplaza (permite re-entrenar sin duplicar filas).
   - Si no existe, lo agrega al DataFrame.
   - Guarda el DataFrame actualizado con `pd.to_pickle()`.

### Agregar un nuevo modelo

Solo se necesita una celda adicional en el notebook:

```python
from sklearn.neighbors import KNeighborsClassifier

knn_metrics = trainer.train_and_save(
    name='knn',
    estimator=KNeighborsClassifier(n_neighbors=5),
    X_train=X_train, X_test=X_test,
    y_train=y_train, y_test=y_test,
    scaler=StandardScaler(),
)
```
<p align="center">
  <img src="Imagenes/Nuevo_modelo.png" alt="API" width="800">
</p>

Luego se inserta automaticamente en la carpeta de los modelos disponibles para la API

<p align="center">
  <img src="Imagenes/modelos_d.png" alt="API" width="800">
</p>

El modelo queda disponible autom√°ticamente en la API sin reiniciar el servicio.

<p align="center">
  <img src="Imagenes/modelo_api_d.png" alt="API" width="800">
</p>

## Descubrimiento de Modelos y M√©tricas en la API

La API no tiene una lista hardcodeada de modelos. En su lugar, descubre din√°micamente qu√© modelos est√°n disponibles y sus m√©tricas cada vez que se hace una petici√≥n.

### Descubrimiento de modelos (`discover_models`)

La funci√≥n `discover_models()` en `API/utils/model_utils.py` escanea el directorio `models/` buscando archivos que coincidan con el patr√≥n `*_model.pkl`:

```python
def discover_models():
    pattern = os.path.join(MODELS_DIR, "*_model.pkl")
    for path in glob.glob(pattern):
        filename = os.path.basename(path)
        name = filename.replace("_model.pkl", "").lower()
        models[name] = path
    return models
```

Esto significa que:
- Cualquier archivo `{nombre}_model.pkl` que `ModelTrainer` guarde en el volumen compartido es detectado autom√°ticamente.
- No se necesita reiniciar la API ni modificar configuraci√≥n alguna.
- Si se elimina un `.pkl`, el modelo deja de aparecer en la siguiente petici√≥n.

### Carga de m√©tricas (`load_metrics`)

La funci√≥n `load_metrics()` lee el archivo `report/model_metrics.pkl` que `ModelTrainer._update_report()` mantiene actualizado:

```python
def load_metrics():
    if os.path.exists(REPORT_PATH):
        df = pd.read_pickle(REPORT_PATH)
        return {
            row["model"].lower(): {
                "train_accuracy": ...,
                "test_accuracy": ...,
                "test_precision": ...,
                "test_recall": ...,
                "test_f1": ...,
            }
            for _, row in df.iterrows()
        }
    return {}
```

Las m√©tricas se actualizan autom√°ticamente porque:
1. `ModelTrainer._update_report()` escribe/actualiza `model_metrics.pkl` en el volumen compartido cada vez que se entrena un modelo.
2. La API lee ese mismo archivo (a trav√©s del volumen Docker `shared_report`) en cada petici√≥n a `GET /models`.
3. Si se re-entrena un modelo, `_update_report()` reemplaza la fila anterior, as√≠ que las m√©tricas siempre reflejan el √∫ltimo entrenamiento.

### Flujo completo


<p align="center">
  <img src="Imagenes/flujo.png" alt="flujo" width="800">
</p


## Pruebas de la API

### Listar modelos disponibles

```bash
curl http://localhost:8000/models
```
<p align="center">
  <img src="Imagenes/API_penguin_classifier.png" alt="Pruebas de la API" width="800">
</p>
Respuesta esperada (despu√©s de entrenar):

```json
{
  "available_models": [
    {
      "name": "gradientboosting",
      "endpoint": "POST /classify/gradientboosting",
      "metrics": { "train_accuracy": 1.0, "test_accuracy": 0.98, ... }
    },
    {
      "name": "randomforest",
      "endpoint": "POST /classify/randomforest",
      "metrics": { ... }
    },
    {
      "name": "svm",
      "endpoint": "POST /classify/svm",
      "metrics": { ... }
    }
  ]
}
```
<p align="center">
  <img src="Imagenes/get_modelos.png" alt="Pruebas de la API" width="800">
</p>


### Clasificar un ping√ºino

```bash
curl -X POST http://localhost:8000/classify/randomforest \
  -H "Content-Type: application/json" \
  -d '{
    "island": 1,
    "bill_length_mm": 39.1,
    "bill_depth_mm": 18.7,
    "flipper_length_mm": 181,
    "body_mass_g": 3750,
    "sex": 1,
    "year": 2007
  }'
```

Respuesta:

```json
{
  "model": "randomforest",
  "species_id": 1,
  "species_name": "Adelie"
}
```
<p align="center">
  <img src="Imagenes/post_modelo.png" alt="Pruebas de la API" width="800">
</p>

### Documentaci√≥n interactiva

FastAPI genera documentaci√≥n Swagger autom√°ticamente en `http://localhost:8000/docs`.

## Registro de Resultados (Logging de Predicciones)

La API registra autom√°ticamente cada predicci√≥n usando la clase `PredictionLogger` (`API/utils/logger.py`).

### C√≥mo funciona

```python
class PredictionLogger:
    def __init__(self, results_dir="results", filename="predictions.log"):
        # Crea el directorio y configura un FileHandler dedicado

    def log(self, input_data: dict, result: dict):
        # Escribe una l√≠nea JSON con timestamp, input y resultado
```

Se instancia una vez al iniciar la API:

```python
pred_logger = PredictionLogger()
```

Y se invoca en cada predicci√≥n exitosa:

```python
pred_logger.log(data.model_dump(), result)
```

### Ejemplo de una l√≠nea en predictions.log

```json
{
  "timestamp": "2025-01-15T14:32:01.123456",
  "input": {
    "island": 1,
    "bill_length_mm": 39.1,
    "bill_depth_mm": 18.7,
    "flipper_length_mm": 181,
    "body_mass_g": 3750,
    "sex": 1,
    "year": 2007
  },
  "result": {
    "model": "randomforest",
    "species_id": 1,
    "species_name": "Adelie"
  }
}
```

### Persistencia del log

El archivo `predictions.log` se almacena en el volumen Docker `shared_results`, montado en `/app/results/` dentro del contenedor de la API. Esto significa que:

- El log sobrevive a reinicios del contenedor (`docker-compose down` + `up`).
- Se pierde solo si se eliminan los vol√∫menes expl√≠citamente (`docker-compose down -v`).
- Cada predicci√≥n se escribe inmediatamente al archivo (no hay buffer), lo que garantiza que no se pierden registros ante un crash del contenedor.

## Mapeo de Variables

| Campo | Tipo | Rango / Valores |
|---|---|---|
| island | int | 1, 2, 3 |
| bill_length_mm | float | 10.0 ‚Äì 100.0 |
| bill_depth_mm | float | 5.0 ‚Äì 35.0 |
| flipper_length_mm | int | 100 ‚Äì 300 |
| body_mass_g | int | 1000 ‚Äì 10000 |
| sex | int | 0 (hembra), 1 (macho) |
| year | int | 2000 ‚Äì 2030 |

Especies: `1` = Adelie, `2` = Chinstrap, `3` = Gentoo

## Vol√∫menes Compartidos

| Volumen | Jupyter | API | Contenido |
|---|---|---|---|
| shared_models | /app/models | /app/models | Archivos .pkl de modelos |
| shared_report | /app/report | /app/report | model_metrics.pkl |
| shared_data | /app/data | ‚Äî | penguins_v1.csv |
| shared_results | /app/results | /app/results | predictions.log |

## Notas

- La API carga modelos din√°micamente: cualquier archivo `*_model.pkl` en el volumen de modelos es detectado sin reiniciar el servicio.
- Las predicciones se registran en `results/predictions.log` con timestamp, input y resultado.
- Si la API se levanta sin modelos entrenados, `GET /models` retorna una lista vac√≠a y `POST /classify/{model}` retorna 404.



## üë• Colaboradores

- üßë‚Äçüíª **Camilo Cort√©s** ‚Äî [![GitHub](https://img.shields.io/badge/GitHub-@cccortesh95-181717?logo=github)](https://github.com/cccortesh95)
- üßë‚Äçüíª **Johnny Casta√±eda** ‚Äî [![GitHub](https://img.shields.io/badge/GitHub-@Johnny--Castaneda--Marin-181717?logo=github)](https://github.com/Johnny-Castaneda-Marin)
- üßë‚Äçüíª **Benkos Triana** ‚Äî [![GitHub](https://img.shields.io/badge/GitHub-@BenkosT-181717?logo=github)](https://github.com/BenkosT)
